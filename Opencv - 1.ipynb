{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"opencv face1.jpeg\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.size\n",
    "# img.shape\n",
    "#nimg = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Detection\n",
    "# start here\n",
    "\n",
    "# cascade classifier function loads pre-trained xml file to detect face\n",
    "facedet = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# converts to grey image\n",
    "greyimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detectMultiScale function detects the face from image and gives x,y,z,w as width and height of rectangle in which face is.\n",
    "faces = facedet.detectMultiScale(img, scaleFactor = 1.05, minNeighbors = 5)\n",
    "x, y, z, w = faces[0]\n",
    "\n",
    "img = cv2.rectangle(img, (x, y), (x+z, y+w), (0, 255, 255), 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "cv2.imshow(\"Face\", img)\n",
    "\n",
    "# waitKey with argument 0 will wait till any key is pressed\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# close the wind\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection in video\n",
    "# start here\n",
    "\n",
    "# VideoCapture is function to capture video\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # video.read() captures video from camera, check is true if capture is allowed, frame is 1st image of video\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    # same code as image detection\n",
    "    # from here\n",
    "    faces = facedet.detectMultiScale(frame, scaleFactor = 1.25, minNeighbors = 5)\n",
    "    for (x, y , w, h) in faces:\n",
    "        frame = cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "#     x, y, z, w = faces[0]\n",
    "    \n",
    "\n",
    "#     frame = cv2.rectangle(frame, (x, y), (x+z, y+w), (0, 255, 255), 2 )\n",
    "    # to here\n",
    "    \n",
    "    # showing each image\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    \n",
    "    # waitKey(1) will return the key pressed and will wait till 1 millisecond\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 58  90  83]\n",
      "  [ 58  92  85]\n",
      "  [ 58  94  87]\n",
      "  ...\n",
      "  [ 51  76 122]\n",
      "  [ 52  76 122]\n",
      "  [ 53  77 123]]\n",
      "\n",
      " [[ 58  90  83]\n",
      "  [ 56  90  83]\n",
      "  [ 56  92  85]\n",
      "  ...\n",
      "  [ 50  75 121]\n",
      "  [ 50  74 120]\n",
      "  [ 51  75 121]]\n",
      "\n",
      " [[ 61  88  83]\n",
      "  [ 57  86  81]\n",
      "  [ 54  85  80]\n",
      "  ...\n",
      "  [ 48  71 119]\n",
      "  [ 49  70 118]\n",
      "  [ 51  72 120]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86  75  28]\n",
      "  [ 86  75  28]\n",
      "  [ 87  77  28]\n",
      "  ...\n",
      "  [ 77  66  55]\n",
      "  [111 100  89]\n",
      "  [126 115 104]]\n",
      "\n",
      " [[ 89  78  33]\n",
      "  [ 86  75  30]\n",
      "  [ 85  74  27]\n",
      "  ...\n",
      "  [ 84  67  62]\n",
      "  [ 85  67  65]\n",
      "  [117  99  97]]\n",
      "\n",
      " [[ 94  83  38]\n",
      "  [ 87  76  31]\n",
      "  [ 81  70  23]\n",
      "  ...\n",
      "  [ 90  73  68]\n",
      "  [ 90  72  70]\n",
      "  [ 89  71  69]]]\n"
     ]
    }
   ],
   "source": [
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
